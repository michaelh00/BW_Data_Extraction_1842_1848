{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for data extraction: Bozner Wochenblatt 1842-1848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "\n",
    "import joblib\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.7\n",
      "OpenCV version: 4.3.0\n",
      "numpy version: 1.19.0\n",
      "pandas version: 1.3.5\n",
      "scikit-image version: 0.17.2\n",
      "Joblib version: 0.16.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Python version: \" + python_version())\n",
    "print(\"OpenCV version: \" + cv2.__version__)\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"scikit-image version: \" + skimage.__version__)\n",
    "print(\"Joblib version: \" + joblib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of the parameters for the pre-mask (exclusion of the top and bottom part of the table). What is considered is what is below param_m_u and above param_m_d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_header_fuss_grenze(img_rgb):\n",
    "    \n",
    "    ### Extraction of table header conturs\n",
    "    img_gr = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bitwise_not(img_gr)\n",
    "    horizontal = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "    cols = horizontal.shape[1]\n",
    "    horizontal_size = cols // 30\n",
    "    horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "    horizontal = cv2.erode(horizontal, horizontalStructure)\n",
    "    horizontal = cv2.dilate(horizontal, horizontalStructure)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(img_rgb.shape[1], 1))\n",
    "    dilated_h = cv2.dilate(horizontal, kernel, iterations=1)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(dilated_h, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    list_y_all_cont = []\n",
    "    for cont in contours: \n",
    "        list_y_cont = []\n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n + 1\n",
    "            y = np.take(cont, a)\n",
    "            list_y_cont.append(y)\n",
    "        list_y_all_cont.append(list_y_cont)\n",
    "    \n",
    "    cont_max_y_all =[]\n",
    "    cont_min_y_all =[]\n",
    "    for item in list_y_all_cont:\n",
    "        item_cont = np.asarray(item)\n",
    "        cont_max_y = item_cont.max()\n",
    "        cont_max_y_all.append(cont_max_y)\n",
    "        cont_min_y = item_cont.min()\n",
    "        cont_min_y_all.append(cont_min_y)\n",
    "    \n",
    "    param_m_u = min(cont_max_y_all, key=lambda x:abs(x-img_rgb.shape[0]/2))\n",
    "    param_m_d = min(cont_min_y_all, key=lambda x:abs(x-img_rgb.shape[0]*0.9))\n",
    "    \n",
    "    return param_m_u, param_m_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of vertical mask parameters (segmentation of the table in columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_verticale_masken(img_rgb, param_m_u, param_m_d):\n",
    "        \n",
    "    ### Premask: image without header\n",
    "    frame = np.full((img_rgb.shape[0], img_rgb.shape[1]), fill_value=255, dtype=np.uint8)\n",
    "    mask_color = (0, 0, 0)\n",
    "    m_u = cv2.rectangle(frame, (0, 0), (img_rgb.shape[1], param_m_u + 2), mask_color, -1) \n",
    "    m_d = cv2.rectangle(frame, (0, param_m_d - 2), (img_rgb.shape[1], img_rgb.shape[0]), mask_color, -1) \n",
    "    m_l = cv2.rectangle(frame, (0, 0), (10, img_rgb.shape[0]), mask_color, -1) \n",
    "    m_r = cv2.rectangle(frame, (img_rgb.shape[1] - 10, 0), (img_rgb.shape[1], img_rgb.shape[0]), mask_color, -1)\n",
    "    vormaske = m_u + m_d + m_l + m_r\n",
    "    \n",
    "    ### Parameters for the main mask Vertical Boxes ###\n",
    "    ### Creation of dilated vertical fields whose contours are further used\n",
    "    hilfsbild_1 = np.full((img_rgb.shape[0], img_rgb.shape[1], img_rgb.shape[2]), fill_value=0, dtype=np.uint8)\n",
    "    masked_img_1 = cv2.bitwise_not(img_rgb, hilfsbild_1, mask=vormaske) \n",
    "    blur_1 = cv2.GaussianBlur(masked_img_1,(3,3), 0, 0)\n",
    "    blur_gr_1 = cv2.cvtColor(blur_1, cv2.COLOR_BGR2GRAY)\n",
    "    ret, out_1 = cv2.threshold(blur_gr_1, 105, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(5, img_rgb.shape[0]))\n",
    "    dilated = cv2.dilate(out_1, kernel, iterations=1)\n",
    "      \n",
    "    ### Extraction of the x-coordinates of the contour points in a list of lists\n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) > 28:\n",
    "        contours_sorted = sorted(contours, key=lambda x: cv2.arcLength(x, True), reverse=True)\n",
    "        contours = contours_sorted[0:28]\n",
    "\n",
    "    cont_max_x_all = []\n",
    "    cont_min_x_all = []\n",
    "\n",
    "    list_x_all_cont = []\n",
    "    for cont in contours: \n",
    "        list_x_cont = []\n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n\n",
    "            x = np.take(cont, a)\n",
    "            list_x_cont.append(x)\n",
    "        list_x_all_cont.append(list_x_cont)\n",
    "    list_x_all_cont.sort()\n",
    "\n",
    "    ### The relevant contours are filtered out of all contours\n",
    "    if len(list_x_all_cont) == 28:\n",
    "        spalte_1 = list_x_all_cont[1]\n",
    "        spalte_2 = list_x_all_cont[3]\n",
    "        spalte_3 = list_x_all_cont[5]\n",
    "        spalte_4 = list_x_all_cont[7]\n",
    "        spalte_5 = list_x_all_cont[9]\n",
    "        spalte_6 = list_x_all_cont[11]\n",
    "        spalte_7 = list_x_all_cont[13]\n",
    "        spalte_8 = list_x_all_cont[16] \n",
    "        spalte_9 = list_x_all_cont[19] \n",
    "        spalte_10 = list_x_all_cont[22]\n",
    "        spalte_11 = list_x_all_cont[24] \n",
    "        spalte_12 = list_x_all_cont[26]\n",
    "\n",
    "        spaltenliste = [spalte_1, spalte_2, spalte_3, spalte_4, spalte_5, spalte_6, spalte_7, \n",
    "                        spalte_8, spalte_9, spalte_10, spalte_11, spalte_12]\n",
    "\n",
    "        masking_params_x = [] \n",
    "        for item in spaltenliste:\n",
    "            item_cont = np.asarray(item)\n",
    "            cont_min_x = item_cont.min()\n",
    "            cont_max_x = item_cont.max()\n",
    "            masking_params_x.append((cont_min_x, cont_max_x))\n",
    "    else: \n",
    "        masking_params_x = [(88,97), (135,141), (207,215), (255,262), (326,335), (376,382), (447,455), \n",
    "                            (521,527), (597,605), (672,681), (795,805), (925,935)]\n",
    "        \n",
    "    return masking_params_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of horizontal mask parameters (table segmentation in rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_horizontale_masken(img_rgb, param_m_u, param_m_d, par_vert_mask):\n",
    "    \n",
    "    ### Help mask: only weather condition data columns\n",
    "    frame = np.zeros((img_rgb.shape[0], img_rgb.shape[1]), dtype=np.uint8)\n",
    "    frame.fill(255)\n",
    "    mask_color = (0, 0, 0)\n",
    "    \n",
    "    m_u = cv2.rectangle(frame, (0, 0), (img_rgb.shape[1], param_m_u), mask_color, -1) \n",
    "    m_d = cv2.rectangle(frame, (0, param_m_d), (img_rgb.shape[1], img_rgb.shape[0]), mask_color, -1) \n",
    "    m_l = cv2.rectangle(frame, (0, 0), ((par_vert_mask[9][1] + 6), img_rgb.shape[0]), mask_color, -1) \n",
    "    m_r = cv2.rectangle(frame, (img_rgb.shape[1], 0), (img_rgb.shape[1], img_rgb.shape[0]), mask_color, -1)\n",
    "    \n",
    "    m_v11 = cv2.rectangle(frame, ((par_vert_mask[10][0] - 6), 0), ((par_vert_mask[10][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v12 = cv2.rectangle(frame, ((par_vert_mask[11][0] - 6), 0), ((par_vert_mask[11][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    \n",
    "    hilfsmaske = m_u + m_d + m_l + m_r + m_v11 + m_v12\n",
    "    \n",
    "    ### Parameters for the main mask Horizontal Boxes ###\n",
    "    ### Creation of dilated horizontal fields whose contours are reused\n",
    "    hilfsbild_0 = np.full((img_rgb.shape[0], img_rgb.shape[1], img_rgb.shape[2]), fill_value=0, dtype=np.uint8)\n",
    "    masked_img_0 = cv2.bitwise_not(img_rgb, hilfsbild_0, mask=hilfsmaske) \n",
    "    blur_0 = cv2.GaussianBlur(masked_img_0,(3,3), 0, 0)\n",
    "    blur_gr_0 = cv2.cvtColor(blur_0, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, out_0 = cv2.threshold(blur_gr_0, 210, 255, cv2.THRESH_BINARY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(int(img_rgb.shape[1]/4), 3))\n",
    "    dilated = cv2.dilate(out_0, kernel, iterations=1)\n",
    "    \n",
    "    ### Extraction of the y-coordinates of the contour points in a list of lists\n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 7:\n",
    "        cont_max_y_all = []\n",
    "        cont_min_y_all = []\n",
    "        list_y_all_cont = []\n",
    "        for cont in contours: \n",
    "            list_y_cont = []\n",
    "            for n in range(0, len(cont)):\n",
    "                a = 2*n + 1\n",
    "                y = np.take(cont, a)\n",
    "                list_y_cont.append(y)\n",
    "            list_y_all_cont.append(list_y_cont)\n",
    "            \n",
    "        for item in list_y_all_cont:\n",
    "            item_cont = np.asarray(item)\n",
    "            cont_max_y = item_cont.max()\n",
    "            cont_min_y = item_cont.min()\n",
    "            cont_max_y_all.append(cont_max_y)\n",
    "            cont_min_y_all.append(cont_min_y)\n",
    "            \n",
    "        cutting_list = [cont_max_y_all[0]]\n",
    "        \n",
    "        for i in range (0,6):\n",
    "            first = int(cont_min_y_all[i])\n",
    "            second = int(cont_max_y_all[i+1])\n",
    "            cutting = int((first + second)/2)\n",
    "            cutting_list.append(cutting)\n",
    "        cutting_list.append(cont_min_y_all[6])\n",
    "    else:\n",
    "        cutting_list = [277, 259, 239, 220, 200, 180, 161, 144]\n",
    "    \n",
    "    return cutting_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishment of the data fields (segmentation of the table in 7 x 12 = 84 boxes (without calendar date fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes_func (img_rgb, parameter_horizontale_masken, parameter_verticale_masken, param_m_u):\n",
    "    \n",
    "    boxlines_h = parameter_horizontale_masken\n",
    "    boxlines_v = parameter_verticale_masken\n",
    "    \n",
    "    frame = np.zeros((img_rgb.shape[0], img_rgb.shape[1]), dtype=np.uint8)\n",
    "    frame.fill(255)\n",
    "    mask_color = (0, 0, 0)\n",
    "\n",
    "    m_u = cv2.rectangle(frame, (0, 0), (img_rgb.shape[1], param_m_u), mask_color, -1)\n",
    "    m_d = cv2.rectangle(frame, (0, (img_rgb.shape[0] - 10)), (img_rgb.shape[1], img_rgb.shape[0]), mask_color, -1) \n",
    "    m_l = cv2.rectangle(frame, (0, 0), ((boxlines_v[0][1] + 6), img_rgb.shape[0]), mask_color, -1) \n",
    "    m_r = cv2.rectangle(frame, (img_rgb.shape[1] - 10, 0), (img_rgb.shape[1], img_rgb.shape[0]), mask_color, -1)\n",
    "\n",
    "    m_v1 = cv2.rectangle(frame, ((boxlines_v[1][0] - 6), 0), ((boxlines_v[1][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v2 = cv2.rectangle(frame, ((boxlines_v[2][0] - 6), 0), ((boxlines_v[2][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v3 = cv2.rectangle(frame, ((boxlines_v[3][0] - 6), 0), ((boxlines_v[3][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v4 = cv2.rectangle(frame, ((boxlines_v[4][0] - 6), 0), ((boxlines_v[4][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v5 = cv2.rectangle(frame, ((boxlines_v[5][0] - 6), 0), ((boxlines_v[5][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v6 = cv2.rectangle(frame, ((boxlines_v[6][0] - 6), 0), ((boxlines_v[6][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v7 = cv2.rectangle(frame, ((boxlines_v[7][0] - 6), 0), ((boxlines_v[7][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v8 = cv2.rectangle(frame, ((boxlines_v[8][0] - 6), 0), ((boxlines_v[8][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "\n",
    "    m_v9 = cv2.rectangle(frame, ((boxlines_v[9][0] - 6), 0), ((boxlines_v[9][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v10 = cv2.rectangle(frame, ((boxlines_v[10][0] - 6), 0), ((boxlines_v[10][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "    m_v11 = cv2.rectangle(frame, ((boxlines_v[11][0] - 6), 0), ((boxlines_v[11][1] + 6), img_rgb.shape[0]), mask_color, -1)\n",
    "\n",
    "    m_h1 = cv2.rectangle(frame, (0, boxlines_h[1]), (img_rgb.shape[1], boxlines_h[1]), mask_color, -1)\n",
    "    m_h2 = cv2.rectangle(frame, (0, boxlines_h[2]), (img_rgb.shape[1], boxlines_h[2]), mask_color, -1)\n",
    "    m_h3 = cv2.rectangle(frame, (0, boxlines_h[3]), (img_rgb.shape[1], boxlines_h[3]), mask_color, -1)\n",
    "    m_h4 = cv2.rectangle(frame, (0, boxlines_h[4]), (img_rgb.shape[1], boxlines_h[4]), mask_color, -1)\n",
    "    m_h5 = cv2.rectangle(frame, (0, boxlines_h[5]), (img_rgb.shape[1], boxlines_h[5]), mask_color, -1)\n",
    "    m_h6 = cv2.rectangle(frame, (0, boxlines_h[6]), (img_rgb.shape[1], boxlines_h[6]), mask_color, -1)\n",
    "\n",
    "\n",
    "    maske = m_u + m_d + m_l + m_r + m_v1 + m_v2 + m_v3 + m_v4 + m_v5 + m_v6 + m_v7 + m_v8 + m_v9 + m_v10 + m_v11 + m_h1 + m_h2 + m_h3 + m_h4 + m_h5 + m_h6\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(maske, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    list_of_boxes = []\n",
    "    for cont in contours:\n",
    "        x_c, y_c, w_c, h_c = cv2.boundingRect(cont)\n",
    "        list_of_boxes.append([x_c, y_c, w_c, h_c])\n",
    "    \n",
    "    return list_of_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted numeric data fields are brought into the standardized format of 30x80 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_form(segm_im):\n",
    "\n",
    "    height, width = (30, 80)\n",
    "\n",
    "    blank_img = np.zeros((height, width, 3), np.uint8)\n",
    "    blank_img[:, 0:width] = (255, 255, 255) # (B, G, R)\n",
    "\n",
    "    x_offset = int((width  - segm_im.shape[1])/2)\n",
    "    y_offset = int((height - segm_im.shape[0])/2)\n",
    "\n",
    "    blank_img[ y_offset:y_offset+segm_im.shape[0], x_offset:x_offset+segm_im.shape[1]] = segm_im\n",
    "    \n",
    "    return blank_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data field segmentation for numeric data fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation of the numeric data fields depending on whether they have 1, 2 or 3 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation of a data field with 3 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dreistellig (im2):\n",
    "\n",
    "    gray_im = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray_im,(1,1), 0, 0)\n",
    "    ret,out= cv2.threshold(blur, 105, 255, cv2.THRESH_BINARY)\n",
    "    out1= cv2.bitwise_not(out)\n",
    "    contours, hierarchy = cv2.findContours(out1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    list_x = []\n",
    "    for cont in contours:    \n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n\n",
    "            x = np.take(cont, a)\n",
    "            list_x.append(x)\n",
    "    minimum_x = np.amin(list_x)\n",
    "    maximum_x = np.amax(list_x)\n",
    "    one_third_x = 1/3 * (maximum_x - minimum_x) + minimum_x\n",
    "\n",
    "    list_x_all_cont = []\n",
    "    for cont in contours: \n",
    "        list_x_cont = []\n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n\n",
    "            x = np.take(cont, a)\n",
    "            list_x_cont.append(x)\n",
    "        list_x_all_cont.append(list_x_cont)\n",
    "\n",
    "    nearest_list = []\n",
    "    for item in list_x_all_cont:\n",
    "        nearest = item[np.abs(item - one_third_x).argmin()] + 1\n",
    "        nearest_list.append(nearest)\n",
    "\n",
    "    nearest_array = np.asarray(nearest_list)\n",
    "\n",
    "    try:\n",
    "        if one_third_x > nearest_array.max():\n",
    "            nearest_bigger = nearest_array.max()\n",
    "        elif one_third_x < nearest_array.min():\n",
    "            nearest_bigger = nearest_array.min()\n",
    "        else:\n",
    "            nearest_bigger = nearest_array[nearest_array >= one_third_x].min()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        if one_third_x < nearest_array.min():\n",
    "            nearest_smaller = nearest_array.min()\n",
    "        elif one_third_x > nearest_array.max():\n",
    "            nearest_smaller = nearest_array.max()\n",
    "        else:\n",
    "            nearest_smaller = nearest_array[nearest_array <= one_third_x].max()  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cutting_x = np.mean([nearest_bigger, nearest_smaller])\n",
    "\n",
    "    y = 0\n",
    "    x = 0\n",
    "    h = len(im2)\n",
    "    w = int(cutting_x)        \n",
    "    processed_1_im2 = im2[y:y+h, x:x+w]\n",
    "\n",
    "    y = 0\n",
    "    x = int(cutting_x)\n",
    "    h = len(im2)\n",
    "    w = im2.shape[1] - x        \n",
    "    processed_2_im2 = im2[y:y+h, x:x+w]\n",
    "\n",
    "    \n",
    "    im3 = processed_2_im2\n",
    "    gray_im = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray_im,(1,1), 0, 0)\n",
    "    ret,out= cv2.threshold(blur, 105, 255, cv2.THRESH_BINARY)\n",
    "    out1= cv2.bitwise_not(out)\n",
    "    contours, hierarchy = cv2.findContours(out1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    list_x = []\n",
    "    for cont in contours:    \n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n\n",
    "            x = np.take(cont, a)\n",
    "            list_x.append(x)\n",
    "    minimum_x = np.amin(list_x)\n",
    "    maximum_x = np.amax(list_x)\n",
    "    one_half_x = 1/2 * (maximum_x - minimum_x) + minimum_x\n",
    "\n",
    "    list_x_all_cont = []\n",
    "    for cont in contours: \n",
    "        list_x_cont = []\n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n\n",
    "            x = np.take(cont, a)\n",
    "            list_x_cont.append(x)\n",
    "        list_x_all_cont.append(list_x_cont)\n",
    "\n",
    "    nearest_list = []\n",
    "    for item in list_x_all_cont:\n",
    "        nearest = item[np.abs(item - one_half_x).argmin()] + 1\n",
    "        nearest_list.append(nearest)\n",
    "\n",
    "    nearest_array = np.asarray(nearest_list)\n",
    "\n",
    "    try:\n",
    "        if one_half_x > nearest_array.max():\n",
    "            nearest_bigger = nearest_array.max()\n",
    "        elif one_half_x < nearest_array.min():\n",
    "            nearest_bigger = nearest_array.min()\n",
    "        else:\n",
    "            nearest_bigger = nearest_array[nearest_array >= one_half_x].min()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        if one_half_x < nearest_array.min():\n",
    "            nearest_smaller = nearest_array.min()\n",
    "        elif one_half_x > nearest_array.max():\n",
    "            nearest_smaller = nearest_array.max()\n",
    "        else:\n",
    "            nearest_smaller = nearest_array[nearest_array <= one_half_x].max()  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cutting_x = np.mean([nearest_bigger, nearest_smaller])\n",
    "\n",
    "    y = 0\n",
    "    x = 0\n",
    "    h = len(im3)\n",
    "    w = int(cutting_x)        \n",
    "    processed_1_im3 = im3[y:y+h, x:x+w]\n",
    "\n",
    "    y = 0\n",
    "    x = int(cutting_x)\n",
    "    h = len(im3)\n",
    "    w = im3.shape[1] - x        \n",
    "    processed_2_im3 = im3[y:y+h, x:x+w]\n",
    "    \n",
    "    return(processed_1_im2, processed_1_im3, processed_2_im3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation of a data field with 2 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zweistellig (im3):\n",
    "\n",
    "    gray_im = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray_im,(1,1), 0, 0)\n",
    "    ret,out= cv2.threshold(blur, 105, 255, cv2.THRESH_BINARY)\n",
    "    out1= cv2.bitwise_not(out)\n",
    "    contours, hierarchy = cv2.findContours(out1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    list_x = []\n",
    "    for cont in contours:    \n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n\n",
    "            x = np.take(cont, a)\n",
    "            list_x.append(x)\n",
    "    minimum_x = np.amin(list_x)\n",
    "    maximum_x = np.amax(list_x)\n",
    "    one_half_x = 1/2 * (maximum_x - minimum_x) + minimum_x\n",
    "\n",
    "    list_x_all_cont = []\n",
    "    for cont in contours: \n",
    "        list_x_cont = []\n",
    "        for n in range(0, len(cont)):\n",
    "            a = 2*n\n",
    "            x = np.take(cont, a)\n",
    "            list_x_cont.append(x)\n",
    "        list_x_all_cont.append(list_x_cont)\n",
    "\n",
    "    nearest_list = []\n",
    "    for item in list_x_all_cont:\n",
    "        nearest = item[np.abs(item - one_half_x).argmin()] + 1\n",
    "        nearest_list.append(nearest)\n",
    "\n",
    "    nearest_array = np.asarray(nearest_list)\n",
    "\n",
    "    try:\n",
    "        if one_half_x > nearest_array.max():\n",
    "            nearest_bigger = nearest_array.max()\n",
    "        elif one_half_x < nearest_array.min():\n",
    "            nearest_bigger = nearest_array.min()\n",
    "        else:\n",
    "            nearest_bigger = nearest_array[nearest_array >= one_half_x].min()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        if one_half_x < nearest_array.min():\n",
    "            nearest_smaller = nearest_array.min()\n",
    "        elif one_half_x > nearest_array.max():\n",
    "            nearest_smaller = nearest_array.max()\n",
    "        else:\n",
    "            nearest_smaller = nearest_array[nearest_array <= one_half_x].max()  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cutting_x = np.mean([nearest_bigger, nearest_smaller])\n",
    "\n",
    "    y = 0\n",
    "    x = 0\n",
    "    h = len(im3)\n",
    "    w = int(cutting_x)        \n",
    "    processed_1_im3 = im3[y:y+h, x:x+w]\n",
    "\n",
    "    y = 0\n",
    "    x = int(cutting_x)\n",
    "    h = len(im3)\n",
    "    w = im3.shape[1] - x        \n",
    "    processed_2_im3 = im3[y:y+h, x:x+w]\n",
    "    \n",
    "    return(processed_1_im3, processed_2_im3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmented characters are brought into the standardized format of 25x25 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_crop(im_rgb):\n",
    "    \n",
    "    gray_im = cv2.cvtColor(im_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray_im,(1,1), 0, 0)\n",
    "    ret,out= cv2.threshold(blur, 220, 255, cv2.THRESH_BINARY)\n",
    "    out1= cv2.bitwise_not(out)\n",
    "    contours, hierarchy = cv2.findContours(out1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    largest_cont = max(contours, key=len)\n",
    "    \n",
    "    largest_cont_x = [i[0][0] for i in largest_cont]\n",
    "    median_largest_cont_x = np.median(largest_cont_x)\n",
    "    min_largest_cont_x = np.amin(largest_cont_x)\n",
    "    max_largest_cont_x = np.amax(largest_cont_x)\n",
    "    \n",
    "    y = 0\n",
    "    x = int(min_largest_cont_x)\n",
    "    h = int(im_rgb.shape[0])\n",
    "    w = int(max_largest_cont_x - min_largest_cont_x)       \n",
    "    processed = im_rgb[y:y+h, x:x+w]\n",
    "    \n",
    "    height, width = (25, 25)\n",
    "    blank_image_0 = np.zeros((height, width, 3), np.uint8)\n",
    "    blank_image_0[:, 0:width] = (255, 255, 255) # (B, G, R)\n",
    "\n",
    "    x_offset = int((width  - processed.shape[1])/2)\n",
    "    y_offset = int((height - processed.shape[0])/2)\n",
    "\n",
    "    blank_image_0[ y_offset:y_offset+processed.shape[0], x_offset:x_offset+processed.shape[1]] = processed\n",
    "    \n",
    "    return blank_image_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format adaptations for the machine learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted numeric data fields are put into a format required for the ML algorithm used for data field segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segm_img(img):\n",
    "    bild = skimage.transform.rescale(img, 1, anti_aliasing=False, multichannel=True, mode='reflect')\n",
    "    bild_2 = np.reshape(bild, (1, 30*80*3))\n",
    "    return bild_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmented characters are put into a format required for the ML algorithm used for optical character recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pred_img(img):\n",
    "    bild = skimage.transform.rescale(img, 1, anti_aliasing=False, multichannel=True, mode='reflect')\n",
    "    bild_2 = np.reshape(bild, (1, 25*25*3))\n",
    "    return bild_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing of descriptive data fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted descriptive data fields are brought into the standardized format of 30x110 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def witt_mitt (img_rgb):\n",
    "    gray_im = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray_im,(17,17), 0, 0)\n",
    "    ret,out= cv2.threshold(gray_im, 100, 255, cv2.THRESH_BINARY)\n",
    "    out1= cv2.bitwise_not(out)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(int(img_rgb.shape[1]/10), 1))\n",
    "    dilated = cv2.dilate(out1, kernel, iterations=1)\n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_cont = max(contours, key=len)\n",
    "    largest_cont_x = [i[0][0] for i in largest_cont]\n",
    "    median_largest_cont_x = np.median(largest_cont_x)\n",
    "    min_largest_cont_x = np.amin(largest_cont_x)\n",
    "    max_largest_cont_x = np.amax(largest_cont_x)\n",
    "\n",
    "    y = 0\n",
    "    x = int(min_largest_cont_x)\n",
    "    h = int(img_rgb.shape[0])\n",
    "    w = int(max_largest_cont_x - min_largest_cont_x)       \n",
    "    processed = img_rgb[y:y+h, x:x+w]\n",
    "\n",
    "    height, width = (30, 110)\n",
    "    output_witt_mitt = np.zeros((height, width, 3), np.uint8)\n",
    "    output_witt_mitt[:, 0:width] = (255, 255, 255) # (B, G, R)\n",
    "\n",
    "    x_offset = int((width  - processed.shape[1])/2)\n",
    "    y_offset = int((height - processed.shape[0])/2)\n",
    "\n",
    "    output_witt_mitt[ y_offset:y_offset+processed.shape[0], x_offset:x_offset+processed.shape[1]] = processed\n",
    "    \n",
    "    return output_witt_mitt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required if post-normalization should be necessary during the analysis process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_form_witt(segm_im):\n",
    "\n",
    "    height, width = (30, 110)\n",
    "\n",
    "    blank_img = np.zeros((height, width, 3), np.uint8)\n",
    "    blank_img[:, 0:width] = (255, 255, 255) # (B, G, R)\n",
    "\n",
    "    x_offset = int((width  - segm_im.shape[1])/2)\n",
    "    y_offset = int((height - segm_im.shape[0])/2)\n",
    "\n",
    "    blank_img[ y_offset:y_offset+segm_im.shape[0], x_offset:x_offset+segm_im.shape[1]] = segm_im\n",
    "    \n",
    "    return blank_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted descriptive data fields are put into a format required for the ML algorithm used for optical pattern recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_witt_feld(img):\n",
    "    bild = skimage.transform.rescale(img, 1, anti_aliasing=False, multichannel=True, mode='reflect')\n",
    "    bild_out = np.reshape(bild, (1, 30*110*3))\n",
    "    return bild_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of trained random forest (RF) algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained random forest algorithms need to be decompressed [(unzipped)](https://support.microsoft.com/en-us/windows/zip-and-unzip-files-f6dde0a7-0fec-8294-e1d3-703ed85e7ebc) from the folder **trained_RF_algorithms_zipped.zip** before use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numeric data field segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_classifier = load(\"1_RFC_algorithm.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optical character recognition (OCR) of segmented characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_classifier = load(\"2_RFC_algorithm.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optical pattern recognition of descripive data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "witt_classifier = load(\"3_RFC_algorithm.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of data from data fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration (boxes):\n",
    "        \n",
    "    witterungsfelder = [0,1,2,12,13,14,24,25,26,36,37,38,48,49,50,60,61,62,72,73,74]  \n",
    "    \n",
    "    datalist = []\n",
    "\n",
    "    for index, box in enumerate(boxes):\n",
    "\n",
    "        try:\n",
    "            height, width = (box[3], box[2])\n",
    "            blank_image = np.zeros((height, width, 3), np.uint8)\n",
    "            blank_image[:, 0:width] = (255, 255, 255) # (B, G, R)\n",
    "\n",
    "            img0 = image\n",
    "\n",
    "            y = box[1]\n",
    "            x = box[0]\n",
    "            h = box[3]\n",
    "            w = box[2]          \n",
    "            img = img0[y:y+h, x:x+w]\n",
    "\n",
    "            a1_1_offset = 0 # x-axis\n",
    "            b1_1_offset = 0 # y-axis\n",
    "\n",
    "            blank_image[b1_1_offset:b1_1_offset+img.shape[0], a1_1_offset:a1_1_offset+img.shape[1]] = img\n",
    "\n",
    "\n",
    "            ### Extraction of the data from the descriptive data fields #########################################################\n",
    "            if index in witterungsfelder:\n",
    "\n",
    "                try:\n",
    "                    outp = witt_mitt(blank_image)\n",
    "\n",
    "                except:\n",
    "                    scale_percent = 90\n",
    "                    width = int(blank_image.shape[1] * scale_percent / 100)\n",
    "                    height = int(blank_image.shape[0] * scale_percent / 100)\n",
    "                    dim = (width, height)\n",
    "                    resized_blank_image = cv2.resize(blank_image, dim, interpolation = cv2.INTER_AREA)\n",
    "                    outp = uni_form_witt(resized_blank_image)\n",
    "\n",
    "                outp_arr = process_witt_feld(outp)\n",
    "\n",
    "                boxkind_pred = witt_classifier.predict(outp_arr)\n",
    "\n",
    "                if boxkind_pred[0] == \"0\":\n",
    "                    prediction = \"detto\"\n",
    "\n",
    "                elif boxkind_pred[0] == \"1\":\n",
    "                        prediction = \"Donnerwetter\"\n",
    "\n",
    "                elif boxkind_pred[0] == \"2\":\n",
    "                    prediction = \"heiter\"\n",
    "\n",
    "                elif boxkind_pred[0] == \"3\":\n",
    "                    prediction = \"Regen\"\n",
    "\n",
    "                elif boxkind_pred[0] == \"4\":\n",
    "                    prediction = \"Schnee\"\n",
    "\n",
    "                elif boxkind_pred[0] == \"5\":\n",
    "                    prediction = \"trueb\"\n",
    "                \n",
    "                elif boxkind_pred[0] == \"6\":\n",
    "                    prediction = \"Wolken\"\n",
    "                \n",
    "                elif boxkind_pred[0] == \"7\":\n",
    "                    prediction = \"Nebel\"\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                output = str(prediction)\n",
    "                datalist.append(output)\n",
    "\n",
    "            ### Extraction of the data from the numeric data fields #############################################################      \n",
    "            else:\n",
    "                \n",
    "                try:\n",
    "                    boxfeatures = uni_form(blank_image)\n",
    "                except:\n",
    "                    scale_percent = 90\n",
    "                    width = int(blank_image.shape[1] * scale_percent / 100)\n",
    "                    height = int(blank_image.shape[0] * scale_percent / 100)\n",
    "                    dim = (width, height)\n",
    "                    resized_blank_image = cv2.resize(blank_image, dim, interpolation = cv2.INTER_AREA)\n",
    "                    boxfeatures = uni_form(resized_blank_image)\n",
    "\n",
    "                boxfeatures_arr = process_segm_img(boxfeatures)\n",
    "                boxkind_pred = segm_classifier.predict(boxfeatures_arr)\n",
    "\n",
    "                if boxkind_pred[0] == \"2\":\n",
    "\n",
    "                    teilung = dreistellig(blank_image)\n",
    "                    erste_ziffer = teilung[0]\n",
    "                    zweite_ziffer = teilung[1]\n",
    "                    dritte_ziffer = teilung[2]\n",
    "\n",
    "                    erste_ziffer_crop = single_crop(erste_ziffer)\n",
    "                    zweite_ziffer_crop = single_crop(zweite_ziffer)\n",
    "                    dritte_ziffer_crop = single_crop(dritte_ziffer)\n",
    "\n",
    "                    erste_ziffer_crop = single_crop(erste_ziffer)\n",
    "                    res_1 = process_pred_img(erste_ziffer_crop)\n",
    "                    ypred_1 = ocr_classifier.predict(res_1)\n",
    "\n",
    "                    zweite_ziffer_crop = single_crop(zweite_ziffer)\n",
    "                    res_2 = process_pred_img(zweite_ziffer_crop)\n",
    "                    ypred_2 = ocr_classifier.predict(res_2)\n",
    "\n",
    "                    dritte_ziffer_crop = single_crop(dritte_ziffer)\n",
    "                    res_3 = process_pred_img(dritte_ziffer_crop)\n",
    "                    ypred_3 = ocr_classifier.predict(res_3)\n",
    "\n",
    "                    if ypred_1[0] == \"-2\":\n",
    "                        prediction_1 = \"\"\n",
    "\n",
    "                    elif ypred_1[0] == \"-1\":\n",
    "                        prediction_1 = \"-\"\n",
    "\n",
    "                    else:\n",
    "                        prediction_1 = ypred_1[0]\n",
    "\n",
    "                    if ypred_2[0] == \"-2\":\n",
    "                        prediction_2 = \"\"\n",
    "\n",
    "                    elif ypred_2[0] == \"-1\":\n",
    "                        prediction_2 = \"-\"\n",
    "\n",
    "                    else:\n",
    "                        prediction_2 = ypred_2[0]\n",
    "\n",
    "                    if ypred_3[0] == \"-2\":\n",
    "                        prediction_3 = \"\"\n",
    "\n",
    "                    elif ypred_3[0] == \"-1\":\n",
    "                        prediction_3 = \"-\"\n",
    "\n",
    "                    else:\n",
    "                        prediction_3 = ypred_3[0]\n",
    "\n",
    "                    output = str(prediction_1) + str(prediction_2) + str(prediction_3)\n",
    "                    datalist.append(output)\n",
    "\n",
    "\n",
    "                elif boxkind_pred[0] == \"1\":\n",
    "\n",
    "                    teilung = zweistellig(blank_image)\n",
    "                    erste_ziffer = teilung[0]\n",
    "                    zweite_ziffer = teilung[1]\n",
    "\n",
    "                    erste_ziffer_crop = single_crop(erste_ziffer)\n",
    "                    res_1 = process_pred_img(erste_ziffer_crop)\n",
    "                    ypred_1 = ocr_classifier.predict(res_1)\n",
    "\n",
    "                    zweite_ziffer_crop = single_crop(zweite_ziffer)\n",
    "                    res_2 = process_pred_img(zweite_ziffer_crop)\n",
    "                    ypred_2 = ocr_classifier.predict(res_2)\n",
    "\n",
    "                    if ypred_1[0] == \"-2\":\n",
    "                        prediction_1 = \"\"\n",
    "\n",
    "                    elif ypred_1[0] == \"-1\":\n",
    "                        prediction_1 = \"-\"\n",
    "\n",
    "                    else:\n",
    "                        prediction_1 = ypred_1[0]\n",
    "\n",
    "                    if ypred_2[0] == \"-2\":\n",
    "                        prediction_2 = \"\"\n",
    "\n",
    "                    elif ypred_2[0] == \"-1\":\n",
    "                        prediction_2 = \"-\"\n",
    "\n",
    "                    else:\n",
    "                        prediction_2 = ypred_2[0]\n",
    "\n",
    "                    output = str(prediction_1) + str(prediction_2)\n",
    "                    datalist.append(output)\n",
    "\n",
    "\n",
    "                elif boxkind_pred == \"0\":\n",
    "\n",
    "                    erste_ziffer = blank_image\n",
    "\n",
    "                    erste_ziffer_crop = single_crop(erste_ziffer)\n",
    "                    res_1 = process_pred_img(erste_ziffer_crop)\n",
    "                    ypred_1 = ocr_classifier.predict(res_1)\n",
    "\n",
    "                    if ypred_1[0] == \"-2\":\n",
    "                        prediction_1 = \"\"\n",
    "\n",
    "                    elif ypred_1[0] == \"-1\":\n",
    "                        prediction_1 = \"-\"\n",
    "\n",
    "                    else:\n",
    "                        prediction_1 = ypred_1[0]\n",
    "\n",
    "                    output = str(prediction_1)\n",
    "                    datalist.append(output)\n",
    "\n",
    "        except:\n",
    "            output = \" \"\n",
    "            datalist.append(output)\n",
    "        \n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the data list for the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_file_structure (days_file, filename, daten):\n",
    "\n",
    "    indexlist_W_21 = [0, 12, 24, 36, 48, 60, 72]\n",
    "    indexlist_W_13 = [1, 13, 25, 37, 49, 61, 73]\n",
    "    indexlist_W_07 = [2, 14, 26, 38, 50, 62, 74]\n",
    "\n",
    "    indexlist_T_21 = [3, 15, 27, 39, 51, 63, 75]\n",
    "    indexlist_T_13 = [4, 16, 28, 40, 52, 64, 76]\n",
    "    indexlist_T_07 = [5, 17, 29, 41, 53, 65, 77]\n",
    "\n",
    "    indexlist_D_21_1 = [6, 18, 30, 42, 54, 66, 78]\n",
    "    indexlist_D_21_2 = [7, 19, 31, 43, 55, 67, 79]\n",
    "\n",
    "    indexlist_D_13_1 = [8, 20, 32, 44, 56, 68, 80]\n",
    "    indexlist_D_13_2 = [9, 21, 33, 45, 57, 69, 81]\n",
    "\n",
    "    indexlist_D_07_1 = [10, 22, 34, 46, 58, 70, 82]\n",
    "    indexlist_D_07_2 = [11, 23, 35, 47, 59, 71, 83]\n",
    "\n",
    "    datalist_W_21 = [daten[x] for x in indexlist_W_21]\n",
    "    datalist_W_13 = [daten[x] for x in indexlist_W_13]\n",
    "    datalist_W_07 = [daten[x] for x in indexlist_W_07]\n",
    "\n",
    "    datalist_T_21 = [daten[x] for x in indexlist_T_21]\n",
    "    datalist_T_13 = [daten[x] for x in indexlist_T_13]\n",
    "    datalist_T_07 = [daten[x] for x in indexlist_T_07]\n",
    "\n",
    "    datalist_D_21_1 = [daten[x] for x in indexlist_D_21_1]\n",
    "    datalist_D_21_2 = [daten[x] for x in indexlist_D_21_2]\n",
    "\n",
    "    datalist_D_13_1 = [daten[x] for x in indexlist_D_13_1]\n",
    "    datalist_D_13_2 = [daten[x] for x in indexlist_D_13_2]\n",
    "\n",
    "    datalist_D_07_1 = [daten[x] for x in indexlist_D_07_1]\n",
    "    datalist_D_07_2 = [daten[x] for x in indexlist_D_07_2]\n",
    "\n",
    "    filename_date = filename[0:10]\n",
    "    date_yymmdd = datetime.datetime.strptime(filename_date, \"%m-%d-%Y\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for i in range (7,0, -1):\n",
    "        day = date.fromisoformat(date_yymmdd)\n",
    "        d = datetime.timedelta(days = i)\n",
    "        dayB = day - d\n",
    "        dayB_conv = date.isoformat(dayB)\n",
    "\n",
    "        day_07 = []\n",
    "        dayB_conv_1 = dayB_conv + \" 07:00:00\"\n",
    "        day_07.append(dayB_conv_1)\n",
    "        day_07.append(datalist_D_07_2[i-1])\n",
    "        day_07.append(datalist_D_07_1[i-1])\n",
    "        day_07.append(datalist_T_07[i-1])\n",
    "        day_07.append(datalist_W_07[i-1])\n",
    "        day_07.append(\"unknown\")\n",
    "\n",
    "        day_13 = []\n",
    "        dayB_conv_2 = dayB_conv + \" 13:00:00\"\n",
    "        day_13.append(dayB_conv_2)\n",
    "        day_13.append(datalist_D_13_2[i-1])\n",
    "        day_13.append(datalist_D_13_1[i-1])\n",
    "        day_13.append(datalist_T_13[i-1])\n",
    "        day_13.append(datalist_W_13[i-1])\n",
    "        day_13.append(\"unknown\")\n",
    "\n",
    "        day_21 = []\n",
    "        dayB_conv_3 = dayB_conv + \" 21:00:00\"\n",
    "        day_21.append(dayB_conv_3)\n",
    "        day_21.append(datalist_D_21_2[i-1])\n",
    "        day_21.append(datalist_D_21_1[i-1])\n",
    "        day_21.append(datalist_T_21[i-1])\n",
    "        day_21.append(datalist_W_21[i-1])\n",
    "        day_21.append(\"unknown\")\n",
    "\n",
    "        days_file.append(day_07)\n",
    "        days_file.append(day_13)\n",
    "        days_file.append(day_21)\n",
    "\n",
    "    return days_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction for one example table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"01-20-1843.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 01-20-1843.png, time required for data extraction: 9.989201307296753 seconds.\n"
     ]
    }
   ],
   "source": [
    "days_file = []\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "image = cv2.imread(filename)\n",
    "header = parameter_header_fuss_grenze(image)[0]\n",
    "fuss = parameter_header_fuss_grenze(image)[1]\n",
    "masking_params_x = parameter_verticale_masken(image, header, fuss)\n",
    "masking_params_y = parameter_horizontale_masken(image, header, fuss, masking_params_x)\n",
    "boxes = boxes_func(image, masking_params_y, masking_params_x, header)\n",
    "\n",
    "daten = iteration(boxes)\n",
    "    \n",
    "days_file = days_file_structure(days_file, filename, daten)\n",
    "        \n",
    "end = time.time()\n",
    "print(\"File: \" + str(filename) + \", time required for data extraction: \" + str(end-start) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Barometer_Zoll</th>\n",
       "      <th>Barometer_Linien</th>\n",
       "      <th>Thermometer</th>\n",
       "      <th>Witterung</th>\n",
       "      <th>manual_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1843-01-13 07:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>trueb</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1843-01-13 13:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>trueb</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1843-01-13 21:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>heiter</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1843-01-14 07:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>Schnee</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1843-01-14 13:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>detto</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1843-01-14 21:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>trueb</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1843-01-15 07:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>detto</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1843-01-15 13:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>detto</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1843-01-15 21:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Schnee</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1843-01-16 07:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Regen</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1843-01-16 13:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Regen</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1843-01-16 21:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>trueb</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1843-01-17 07:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>-</td>\n",
       "      <td>-2</td>\n",
       "      <td>trueb</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1843-01-17 13:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>heiter</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1843-01-17 21:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>heiter</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1843-01-18 07:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>detto</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1843-01-18 13:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>trueb</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1843-01-18 21:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>detto</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1843-01-19 07:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>detto</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1843-01-19 13:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>heiter</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1843-01-19 21:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>-0</td>\n",
       "      <td>trueb</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime Barometer_Zoll Barometer_Linien Thermometer Witterung  \\\n",
       "0   1843-01-13 07:00:00             26                5          -2     trueb   \n",
       "1   1843-01-13 13:00:00             26                5           4     trueb   \n",
       "2   1843-01-13 21:00:00             26                6           0    heiter   \n",
       "3   1843-01-14 07:00:00             26                5          -2    Schnee   \n",
       "4   1843-01-14 13:00:00             26                6           6     detto   \n",
       "5   1843-01-14 21:00:00             26                5          -2     trueb   \n",
       "6   1843-01-15 07:00:00             26                5          -3     detto   \n",
       "7   1843-01-15 13:00:00             26                4           4     detto   \n",
       "8   1843-01-15 21:00:00             26                4           1    Schnee   \n",
       "9   1843-01-16 07:00:00             26                3           2     Regen   \n",
       "10  1843-01-16 13:00:00             26                3           5     Regen   \n",
       "11  1843-01-16 21:00:00             26                8           0     trueb   \n",
       "12  1843-01-17 07:00:00             27                -          -2     trueb   \n",
       "13  1843-01-17 13:00:00             27                -           4    heiter   \n",
       "14  1843-01-17 21:00:00             27                3           0    heiter   \n",
       "15  1843-01-18 07:00:00             27                3           0     detto   \n",
       "16  1843-01-18 13:00:00             27                5           4     trueb   \n",
       "17  1843-01-18 21:00:00             27                5           1     detto   \n",
       "18  1843-01-19 07:00:00             27                4           1     detto   \n",
       "19  1843-01-19 13:00:00             27                3           6    heiter   \n",
       "20  1843-01-19 21:00:00             27                3          -0     trueb   \n",
       "\n",
       "   manual_corr  \n",
       "0      unknown  \n",
       "1      unknown  \n",
       "2      unknown  \n",
       "3      unknown  \n",
       "4      unknown  \n",
       "5      unknown  \n",
       "6      unknown  \n",
       "7      unknown  \n",
       "8      unknown  \n",
       "9      unknown  \n",
       "10     unknown  \n",
       "11     unknown  \n",
       "12     unknown  \n",
       "13     unknown  \n",
       "14     unknown  \n",
       "15     unknown  \n",
       "16     unknown  \n",
       "17     unknown  \n",
       "18     unknown  \n",
       "19     unknown  \n",
       "20     unknown  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(days_file, columns=[\"datetime\", \"Barometer_Zoll\", \"Barometer_Linien\", \"Thermometer\", \"Witterung\", \"manual_corr\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"result_example_raw_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this Python Jupyter notebook is inspired by and adapted from the following sources (last access 15.09.2022): \n",
    "\n",
    "Image Processing Techniques:  \n",
    "https://docs.opencv.org/4.x/d2/d96/tutorial_py_table_of_contents_imgproc.html  \n",
    "https://stackoverflow.com/questions/14063070/overlay-a-smaller-image-on-a-larger-image-python-opencv  \n",
    "\n",
    "Machine Learning Techniques:  \n",
    "https://scikit-learn.org/stable/  \n",
    "https://www.tensorflow.org/tutorials  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python Jupyter notebook uses Python OpenCV (https://github.com/opencv/opencv-python), numpy (https://github.com/numpy/numpy), pandas (https://github.com/pandas-dev/pandas), scikit-image (https://github.com/scikit-image/scikit-image) and joblib (https://github.com/joblib/joblib). The code functionality was developed with the additional use of scikit-learn (https://github.com/scikit-learn/scikit-learn), tensorflow (https://github.com/tensorflow/tensorflow) and matplotlib (https://github.com/matplotlib/matplotlib)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data source for the data extraction is the [Bozner Wochenblatt](https://digital.tessmann.it/tessmannDigital/Zeitungsarchiv/Jahresuebersicht/Zeitung/2) (later Bozner Zeitung) for the period 1842 - 1848 (last access 15.09.2022. License: [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
